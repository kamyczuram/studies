# -*- coding: utf-8 -*-
"""Mateusz_Kamyczura_Projekt_BoML-checkpoint.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QBwN16VjgwzoyvM6IRwjhc8_dwjYBMCN

## Loading Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import GridSearchCV
import tensorflow.keras as keras
from keras.models import Sequential
from keras.wrappers.scikit_learn import KerasRegressor
from keras.layers import Dense

"""## Data Preparing"""

df = pd.read_csv("student-mat.csv")
df.isnull().sum()

"""### data cleaning"""

df=df.drop(['school', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',
       'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',
       'higher','G1','G3'], axis=1)
df.dtypes

df

"""### mapping values into binary"""

sex_mapping = {"M":0,
                "F":1}
i_r_mapping = {"yes":1,
                "no":0}

df["sex"]=df["sex"].map(sex_mapping)
df["internet"]=df["internet"].map(i_r_mapping)
df["romantic"]=df["romantic"].map(i_r_mapping)

df

"""### corelation plot"""

plt.figure()
sns.heatmap(df.corr())
plt.show()

X = df.drop("G2", axis=1)
y = df["G2"]

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)

"""## KNN"""

KNN = KNeighborsClassifier(n_neighbors=10)
KNN = KNN.fit(X_train,y_train)
mean_squared_error(KNN.predict(X_test), y_test)

param_range = np.linspace(1, 200, 200, dtype=np.int)
scores_train = []
scores_test = []

"""### counting mse for diffrent values of neighbors"""

for param in param_range:
    KNN = KNeighborsClassifier(n_neighbors=param)
    KNN = KNN.fit(X_train,y_train)
    tmp_score = mean_squared_error(KNN.predict(X_test), y_test)
    scores_test.append(tmp_score)
    tmp_score = mean_squared_error(KNN.predict(X_train), y_train)
    scores_train.append(tmp_score)

"""### making a plot for scores from above"""

plt.figure(figsize=(7,5))

plt.plot(scores_train, color= "b")
plt.plot(scores_test, color= "r")

plt.xlabel('number of neighbors')
plt.ylabel('mse')

plt.show()

"""## Logistic Regression"""

lr = LogisticRegression()
standardScaler = StandardScaler()
pca = PCA(n_components=3)

standardScaler = standardScaler.fit(X_train)
pca = pca.fit(standardScaler.transform(X_train))

lr = lr.fit(pca.transform(standardScaler.transform(X_train)), y_train)
mean_squared_error(lr.predict(pca.transform(standardScaler.transform(X_test))), y_test)

"""## Grid Search for Neural Networks

### model creating for Grid Search
"""

def create_model(activation='relu'):
    model = Sequential()
    model.add(Dense(32, input_dim=14, kernel_initializer='uniform', activation=activation))
    model.add(Dense(16,  kernel_initializer='uniform', activation='relu'))
    model.add(Dense(8,  kernel_initializer='uniform', activation='relu'))
    model.add(Dense(1, kernel_initializer='uniform'))
    model.compile(loss='mse', metrics=[keras.metrics.MeanSquaredError()])
    return model

"""### making grid of params"""

model = KerasRegressor(build_fn=create_model, verbose=0)
activation = ['relu', 'tanh', 'sigmoid']
batch_size = [8, 10, 16]
epochs = [50, 70 , 90, 110]
param_grid = dict(activation=activation, batch_size=batch_size, epochs=epochs)

"""### fitting  model for our data"""

grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, scoring='neg_mean_squared_error')
grid_result = grid.fit(X_train, y_train, validation_data=(X_test,y_test))

"""### finding best model, and showing results for each"""

print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

"""### extracting best params"""

best_activation = grid_result.best_params_['activation']
best_batch_size = grid_result.best_params_['batch_size']
best_epochs = grid_result.best_params_['epochs']
# best_epochs = 200

"""### creating model with best params"""

model = Sequential()
model.add(Dense(32, input_dim=14, kernel_initializer='uniform', activation=best_activation))
model.add(Dense(16,  kernel_initializer='uniform', activation='relu'))
model.add(Dense(8,  kernel_initializer='uniform', activation='relu'))
model.add(Dense(1, kernel_initializer='uniform'))
model.compile(loss='mae', metrics=[keras.metrics.MeanSquaredError()])
model.summary()

history = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs = best_epochs, verbose=1, batch_size=best_batch_size)

"""### Plot of mae and mse for this model"""

plt.figure(figsize=(7,5))

plt.plot(range(best_epochs), history.history['loss'], color= "b")
plt.plot(range(best_epochs), history.history['val_loss'], color= "r")

plt.xlabel('epoch')
plt.ylabel('mse')

plt.show()

plt.figure(figsize=(7,5))

plt.plot(range(best_epochs), history.history['mean_squared_error'], color= "b")
plt.plot(range(best_epochs), history.history['val_mean_squared_error'], color= "r")

plt.xlabel('epoch')
plt.ylabel('mae')

plt.show()

"""### Reccomend : You can change number of neurons in first layer in Grid Search to eg. [16,32,64]

Apparently los main file :/
"""



